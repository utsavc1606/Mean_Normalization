{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab you will be performing a particular form of feature scaling known as *mean normalization*. Mean normalization will not only scale the data but will also ensure your data has zero mean. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0, 5001, (1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.mean(X, axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X - ave_cols)/std_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.45535839e-17  -1.58650870e-16  -1.26898492e-16  -1.08579812e-16\n",
      "   1.66533454e-17  -5.12923037e-17   5.06261699e-17  -9.80882042e-17\n",
      "  -6.55031585e-17   1.25344179e-16   1.55320201e-16   3.24185123e-17\n",
      "   6.21724894e-17  -5.72875081e-17  -3.16691118e-17  -6.62803146e-17\n",
      "  -4.11892742e-17  -8.22675261e-17   2.22044605e-17  -1.15685239e-16]\n",
      "[-1.7778388  -1.7541885  -1.72843159 -1.6629704  -1.70997632 -1.71831195\n",
      " -1.7363688  -1.69837986 -1.74584155 -1.69804162 -1.67935101 -1.78613914\n",
      " -1.74410013 -1.73521634 -1.75337061 -1.67247844 -1.76090954 -1.76984842\n",
      " -1.76218208 -1.74385421]\n",
      "[ 1.65084767  1.76426153  1.70584949  1.76288242  1.72853131  1.66189527\n",
      "  1.6689241   1.72716237  1.7482172   1.77338831  1.69233494  1.73480653\n",
      "  1.68235253  1.6961292   1.72131683  1.74300151  1.69129991  1.7205453\n",
      "  1.7685601   1.72716331]\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(np.mean(X_norm, axis=0))\n",
    "# Print the minimum value of each column of X_norm\n",
    "print(np.min(X_norm, axis=0))\n",
    "# Print the maximum value of each column of X_norm\n",
    "print(np.max(X_norm, axis=0 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 0, 1, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[758 608 207 937 983 797 837 111 974 268 765 439 385 102 637 500 854 496\n",
      " 543 836 631 559 895 200 337  45 939 383 334 801  42  12 716 436 213 614\n",
      "  26 322 267 255 220 377 358 233 402 826 619 651 306 963 998 460  34 529\n",
      " 266 601 540 320 313 746 902 502 932 640 510 890  86 427 864 790 676 324\n",
      " 258 693 715 791 101 650 970 923 251 925 635 116 544 595 707 754 238 861\n",
      " 805 620 182 319  14 649 604 539 897 112 298 197 538 782 271 851 371 590\n",
      " 341 847 862 645 618 883 927 234 735 907   0 507 422 764 554 849  95 428\n",
      " 335 452 886  49 174 374 738 901 779 195 244 318 709   2 844 379 443   7\n",
      " 246 494 593 744 840 789 198 817 768 290  21 566 121 119 194 323 809 403\n",
      "   8 488 491 467 638 257 761 463 426 456 888 457 157 904 201 473 933 516\n",
      " 912 103 176 705 228 569 623 697 684 986 763 777 418 332 333 400 390 760\n",
      " 520 219 479 215 833 701  43 687 350 150 445 508 177 386 276 866 280 381\n",
      " 606 314 277 223 842 793 818 499 795 120 513 211 653 928 423  69 938 772\n",
      " 152 750 876 551 984 741 739 535 767 179 660 487 834 511 447  31 448 753\n",
      " 930 682 948 530 186 331 243 622 625  92 501 481 162 553 521 493 643 316\n",
      " 557 832 127 924 798 169 477 857 522 372 548 254 766 450 474 263 470  79\n",
      " 565 478 785 269 503 776 573  27  36 225 976 584 378 449 773 437 360 396\n",
      " 865 468 237 794 387  38 133 745 517 421 282 576 248 472 556 712  97 475\n",
      " 497 882 934 683 285 482 702 273 505  15 594 784 253 388 165 435 978 596\n",
      " 603 330 564 311 329 105 662 515 406 241 317  77 717 562 291 909 178 561\n",
      " 221 977 679 550 302 242 570 526 362 106 945 492 592 722 633 571  99 677\n",
      " 954 646 871 144 187 831 134 591 980 607 692 965 958 788 419 959 395 149\n",
      " 546  58 417  10 168 464 184 956 916 913 893 420  74 690  62  18 114 757\n",
      " 999 145 286 656 293 681 969 270 961 740 731 695 541 742 304  83  71 289\n",
      " 167 874   6 911  20 287 392 122 822  81 989 278 424 136 889 859 118 581\n",
      " 714   3 673 504 547  78 239 272 274 180 373 252 674 485 365 825 669 458\n",
      " 710 752 641  75  13 533 979 175 534 440 814 352 409  52 129 429 441 860\n",
      " 353  35 250 171 399 968 685 719 892 412 192 872 577 589 634 188 227 878\n",
      " 675 434 723 151 627 189 587 652 610 408 747 616 949 442 536 326 321 713\n",
      " 846 688 918 654 800 525 542 664 296 759 605 708 919  25 231 405 325  23\n",
      " 855 819 204 107 706 802  46 696 898 163 771 611   9 971  80 853 212 366\n",
      " 848 307 142 808  85 661  55 588 139 265 630 240 484 835 856 126 299 256\n",
      " 193 413 931 962 108 994 910 104 514 993 275  30 966 527 762 733 343 816\n",
      " 991 699 156 303 153  82 755 519 867   4 430 943 380 226 154 734 471 518\n",
      " 309 881  94 807 870 202 774 838  91  96 810  72 841 824 786 100 642 224\n",
      " 792 349 572 523 261 629 665 346 148 407 778 563 815 827 465 729 921 483\n",
      " 490 351 357 438  65  84 997 900 686 574 582 823 454 903 680 783 297  66\n",
      " 567 356  44 281 804 732  16  64 279 143 375 655  19 780 160 124 988  98\n",
      " 411 469  61 666 799 166 338 615 537 891 667 820 981 990 549  90 678 636\n",
      " 863 775 295 982 917 612  76 942  57 344 858 720 117 915 944 444 617 414\n",
      " 700 936 585 264 728 208  51 216 599 509 489 340 262 455  48 648  29 721\n",
      " 663 308 446 315 955 787 885 453 466 113  67 578 498 115  28 597  22 361\n",
      "   5  88 147  59 217 575  73 957 952 580 135 568 461 703 305 995 345 451\n",
      " 724 796  37 190 670 905 416  60 972 626 743 230 843 130  11 914 725 140\n",
      " 600 393 232 975 425 245 644  47 806  70 284  53 146 672  54  87 659 671\n",
      " 247 367 506 173 908 852 294 249 397 613 769 236 887 598 920 495 125 922\n",
      " 698 301 312 552 748 158 812 292 869  24 609 532 558 528 235 209 141 941\n",
      " 803  39 839 560 992 730 170 621 109 879 830 259 960 196 370 579 935 726\n",
      " 940 394 137 229 987 161 398 868 639  17 555 850 736 391 877 206 355 973\n",
      " 964 689 310 781 328 401 967 164 191 382 431 953 480 359 632 711 926 218\n",
      " 583 110 462 410 183 415 737 222  89 647 951 132 348   1 813 288 821 138\n",
      " 896 950  40 929 128 545 657 996 433 749 751 668 906 369 512 364 884 123\n",
      " 203  68 354 718 339 347 384 327 985 829 880 704 459 336 368 947 363  41\n",
      " 845 828  56 205 894 694 404 185 691 260 770 432 283 199 389 531 300 624\n",
      " 628 376  50 214  93 476 486 155 658 873 899  33 159 524 342 811 210  32\n",
      " 727 946 586  63 756 602 181 172 131 875]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09198215 -1.49296277 -1.51357382 ...,  1.01030295  0.09181206\n",
      "  -1.5152784 ]\n",
      " [-1.65359611 -0.33117719 -0.57150514 ..., -0.26198156 -1.01349458\n",
      "   1.26862217]\n",
      " [-0.48461652  0.04270653  0.02004237 ..., -0.63597728 -0.93408833\n",
      "  -1.09703329]\n",
      " ..., \n",
      " [ 1.5938745   1.39601071 -0.34011985 ...,  1.38429868 -1.62109419\n",
      "  -0.51065643]\n",
      " [-1.07700018  0.98973781  0.59161913 ...,  0.96346611  1.01420073\n",
      "  -0.6836515 ]\n",
      " [ 0.98638951 -0.21640686  1.43452269 ...,  0.36856824  0.2669312\n",
      "  -0.32446094]]\n"
     ]
    }
   ],
   "source": [
    "print(X_norm[row_indices[0:600]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[row_indices[:600]]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[row_indices[600:800]]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[row_indices[800:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
